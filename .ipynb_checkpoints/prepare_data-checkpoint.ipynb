{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "534108bc",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import geopandas as gpd\n",
    "from utils import *\n",
    "import fiona\n",
    "import rasterio.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3f3b34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea9b7654",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/train_summer/images_gt'\n",
    "samples_dir='data/summer_tiles_300'\n",
    "\n",
    "patch_size=300\n",
    "\n",
    "use_AOI = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03f8b5b",
   "metadata": {},
   "source": [
    "# Processing for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e38b66d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train_summer/images_gt/trees_afs_summer_6_Almetjevsk_CIMA_gpx_H\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 1/8 [00:15<01:50, 15.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train_summer/images_gt/trees_afs_summer_3_HMAO_CIMA_gpx_H\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 2/8 [00:52<02:48, 28.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train_summer/images_gt/trees_afs_summer_10_Baykalsk_CIMA_gpx_H\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 3/8 [01:09<01:56, 23.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train_summer/images_gt/trees_afs_summer_8_Baykalsk_CIMA_gpx_H\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 4/8 [01:17<01:08, 17.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train_summer/images_gt/trees_afs_summer_7_Baykalsk_CIMA_gpx_H\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 5/8 [01:29<00:45, 15.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train_summer/images_gt/trees_afs_summer_9_Baykalsk_CIMA_gpx_H\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 6/8 [01:51<00:34, 17.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train_summer/images_gt/trees_afs_summer_1_HMAO_CIMA_gpx_H\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 7/8 [02:00<00:14, 14.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train_summer/images_gt/trees_afs_summer_4_HMAO_CIMA_gpx_H\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [03:04<00:00, 23.09s/it]\n"
     ]
    }
   ],
   "source": [
    "def create_train_ds(input_dir, resulting_ds_dir):\n",
    "    \"\"\"\n",
    "    Preparing data for training by splitting big input images into tiles\n",
    "    \n",
    "        Args:\n",
    "            input_dir: directory, which contains directories with data that will be used for training\n",
    "            resulting_ds_dir: directory for resulting splitted images\n",
    "    \"\"\"\n",
    "    for p in tqdm(os.listdir(input_dir)):\n",
    "        path = os.path.join(data_path,p)\n",
    "        print(path)\n",
    "        for file in os.listdir(path):\n",
    "            if file.endswith(\".shp\"):\n",
    "                orig = gpd.read_file(os.path.join(path, file))\n",
    "            if file.endswith('.tif'):\n",
    "                file_3chanel = \"three_\"+file\n",
    "                with rasterio.open(os.path.join(path,file)) as rast:\n",
    "                    meta = rast.meta\n",
    "                    out_image=rast.read()\n",
    "                    if use_AOI:\n",
    "                        path_AOI = os.path.join(os.path.join(input_dir.split('/images')[0], 'AOI'),path.split('/')[-1])\n",
    "                        path_AOI = os.path.join(path_AOI,path.split('/')[-1].split('_gpx_H')[0]+\"_gpx_AOI.shp\")\n",
    "                        with fiona.open(path_AOI, \"r\") as shapefile:\n",
    "                            shapes = [feature[\"geometry\"] for feature in shapefile]\n",
    "                            out_image, out_transform = rasterio.mask.mask(rast, shapes)\n",
    "        with rasterio.open(file_3chanel,'w', **meta) as new_dataset:\n",
    "            new_dataset.write(out_image)\n",
    "\n",
    "        original_data = orig['geometry'].bounds.apply(inv_affine, 1, file_name=file_3chanel, meta=meta, label='Tree')\n",
    "        original_data.to_csv(f\"{p}_before_proc.csv\")\n",
    "        train_annotations= split_raster(path_to_raster=file_3chanel,\n",
    "                                     annotations_file=f\"{p}_before_proc.csv\",\n",
    "                                     base_dir=resulting_ds_dir,\n",
    "                                     patch_size=patch_size,\n",
    "                                     patch_overlap=0.25, allow_empty=True)\n",
    "        \n",
    "        os.remove(file_3chanel)\n",
    "        os.remove(f\"{p}_before_proc.csv\")\n",
    "\n",
    "    final_df = None\n",
    "    for csv in os.listdir(samples_dir):\n",
    "        if csv.endswith(\".csv\"):\n",
    "            processed = pd.read_csv(os.path.join(resulting_ds_dir,csv)).dropna().reset_index().drop(['index'],axis=1)\n",
    "\n",
    "            if final_df is None:\n",
    "                final_df = processed\n",
    "            else:\n",
    "                final_df = final_df.append(processed)\n",
    "    final_df.to_csv(os.path.join(resulting_ds_dir,'final_df.csv'))\n",
    "    \n",
    "create_train_ds(data_path, samples_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cbdb310",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# perfroming train/test split by images\n",
    "\n",
    "train_val_test = pd.read_csv(os.path.join(samples_dir,'final_df.csv'))\n",
    "\n",
    "train_val_test['label'] = 'Tree'\n",
    "\n",
    "train_val_paths, test_paths = train_test_split(train_val_test['image_path'].unique(), test_size=0.15, random_state=42)\n",
    "train_val = train_val_test[train_val_test['image_path'].isin(train_val_paths)]\n",
    "test = train_val_test[train_val_test['image_path'].isin(test_paths)]\n",
    "train_val.to_csv(os.path.join(samples_dir,\"train_val.csv\"))\n",
    "test.to_csv(os.path.join(samples_dir,'test.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
